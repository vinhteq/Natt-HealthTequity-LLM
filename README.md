# ğŸ§© HealthTequity Case Study: Voice-Based Health Analytics Pipeline

This project showcases a **voice-enabled AI pipeline** where Spanish-language medical questions are answered using **GPTâ€‘4o** and grounded in a personalized **blood pressure dataset**. It integrates **speech recognition (ASR)**, **translation**, **text-to-speech (TTS)**, and **LLM-based reasoning** into one seamless workflow.

---

## ğŸ”§ Project Structure

The pipeline is implemented across **three Jupyter notebooks**, each responsible for a key step in the data generation and question-answering process.

---

### ğŸ“˜ Notebook 1: `Generate_Synthetic_BP_Dataset.ipynb`

Generates a **synthetic 30-day blood pressure dataset** for an older adult.  
It simulates realistic fluctuations between normal and hypertensive readings and produces a structured CSV.

**Key Functions**
- Randomly generates systolic/diastolic readings by date
- Includes demographic information (age, sex)
- Saves reproducible CSV for downstream tasks

#### ğŸ—‚ï¸ Outputs:
/data/synthetic_csv/synthetic_bp_95_female.csv


---

### ğŸ“˜ Notebook 2: `Generate_Spanish_Audio.ipynb`

Processes a list of English questions and performs the following:

- ğŸŒ **Translates** them into Spanish using `deep-translator`
- ğŸ”Š **Generates Spanish audio** (.wav) with `gTTS`
- ğŸ§¾ Creates a `ground_truth.csv` linking each audio file to its Spanish transcription

#### ğŸ—‚ï¸ Outputs:
/data/synthetic_csv/ground_truth.csv
/data/Spanish_audio/*.wav


---

### ğŸ“˜ Notebook 3: `Run_Audio_QA_Pipeline.ipynb` (Main Pipeline)

This notebook orchestrates the **end-to-end voice-to-insight flow**:

#### ğŸ”¹ Steps
1. **Transcription (ASR)** â€“ Transcribes Spanish audio using OpenAI Whisper  
2. **Translation** â€“ Converts Spanish â†’ English (using Whisper or GPT-4o)  
3. **Question Answering** â€“ Uses GPT-4o to analyze the blood-pressure CSV and answer each question  
4. **Speech Synthesis** â€“ Generates Spanish audio answers via gTTS  
5. **Evaluation** â€“ Computes WER / CER / SER metrics for input and output  
6. **Visualization** â€“ Compares ASR performance via a bar-chart summary  

#### ğŸ“¥ Inputs:
- `synthetic_bp_*.csv` (blood pressure data)
- `*.wav` files
-  `ground_truth.csv` (for ASR evaluation)

#### ğŸ—‚ï¸ Outputs:
/results/llm_outputs/pipeline_results.csv â† full Q&A mapping
/results/tts_audio/answer_.wav â† synthesized Spanish answers
/results/evaluation_metrics/.csv â† WER / CER / SER scores
/results/evaluation_metrics/asr_comparison.png


---

---

## âš™ï¸ Technologies Used

| Component | Purpose | Tool |
|------------|----------|------|
| **ASR** | Speech-to-text for Spanish audio | OpenAI Whisper |
| **Translation** | Spanish â†’ English or vice versa | Whisper / GPT-4o-mini |
| **LLM Reasoning** | Medical Q&A grounded in blood-pressure data | GPT-4o-mini |
| **TTS** | Spanish speech generation | gTTS + pydub |
| **Evaluation** | Computes WER / CER / SER metrics | JiWER + Levenshtein |
| **Visualization** | Displays comparative ASR accuracy | Matplotlib |

---

## ğŸ—‚ Folder Structure (Simplified)

```text
HealthTequity-LLM/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ synthetic_csv/              â† CSV datasets + ground truth
â”‚   â””â”€â”€ Spanish_audio/              â† Input audio questions
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ llm_outputs/                â† GPT answers and translations
â”‚   â”œâ”€â”€ tts_audio/                  â† Generated Spanish answers
â”‚   â””â”€â”€ evaluation_metrics/         â† WER/CER/SER + charts
â”‚
â”œâ”€â”€ Generate_Synthetic_BP_Dataset.ipynb
â”œâ”€â”€ Generate_Spanish_Audio.ipynb
â””â”€â”€ Run_Audio_QA_Pipeline.ipynb


## ğŸ“Š Flow Diagram

<p align="center">
  <img src="./assets/pipeline_diagram.png" width="900">
  <br>
  <em>End-to-end voice-to-insight pipeline integrating ASR, translation, LLM reasoning, and TTS.</em>
</p>

